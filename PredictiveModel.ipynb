{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "#from pyimagesearch.lenet import LeNet\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\n",
    "\t\t# first set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "\t\t# second set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "\t\t# third set of CONV => RELU => POOL layers\n",
    "\t\tmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "              \n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(1000))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the number of epochs to train for, init learning rate and batch size\n",
    "EPOCHS = 50\n",
    "INIT_LR = 1e-3\n",
    "BS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# init the image suffix, yset, and image list\n",
    "print(\"[INFO] loading images...\")\n",
    "suffix = '.jpg'\n",
    "img_list = []\n",
    "yset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels list and 2 dicts for 2 way mapping\n",
    "labels = []\n",
    "# key = label value = number\n",
    "label_yval = dict()\n",
    "# key = number value = label\n",
    "yval_label = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Cells\n",
    "csv_file = 'balthus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use csv file to grab images/labels\n",
    "df = pd.read_csv(csv_file)\n",
    "nameCol = df['#img']\n",
    "predCol = df['Style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all fabric columns to the y set\n",
    "for i in range (0,len(predCol)):\n",
    "    labels.append(predCol[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all unique labels\n",
    "uni_labels = set(labels)\n",
    "uni_labels = list(uni_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign each label a dict key number\n",
    "for i in range(0,len(uni_labels)):\n",
    "    yval_label[i] = uni_labels[i]\n",
    "    label_yval[uni_labels[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cityscape': 4,\n",
       " 'genre painting': 3,\n",
       " 'landscape': 7,\n",
       " 'literary painting': 9,\n",
       " 'nude painting (nu)': 5,\n",
       " 'portrait': 2,\n",
       " 'self-portrait': 6,\n",
       " 'sketch and study': 8,\n",
       " 'still life': 0,\n",
       " 'symbolic painting': 1}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_yval[labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of keys associated with their labels\n",
    "for i in range (0, len(labels)):\n",
    "    yset.append(label_yval[labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove text and leave fabric cave number for labels and zero index\n",
    "#for i in range (0,len(yset)):\n",
    "#    yset[i] = int(re.sub(\"\\D\", \"\", yset[i]))\n",
    "#    yset[i] = yset[i]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather images from path created from file names in csv file\n",
    "for i in range (0,len(nameCol)):\n",
    "    base_filename = nameCol[i]\n",
    "    fileName = os.path.join(\"./images3/\", base_filename + suffix)\n",
    "    im = cv2.imread(fileName)\n",
    "    im = cv2.resize(im, (28,28))\n",
    "    im = img_to_array(im)\n",
    "    img_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "p = np.random.permutation(len(yset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(yset)):\n",
    "    Y.append(yset[p[i]])\n",
    "    X.append(img_list[p[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the test and training set 75:25\n",
    "split = int(len(X)*(.75))\n",
    "xtrain = X[:split]\n",
    "xtest = X[split:]\n",
    "ytrain = Y[:split]\n",
    "ytest = Y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to arrays\n",
    "trainX = np.array(xtrain, dtype=\"float\")/225.0\n",
    "testX = np.array(xtest, dtype =\"float\")/225.0\n",
    "\n",
    "ytrain = np.array(ytrain)\n",
    "ytest = np.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 28, 28, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed Y data containers\n",
    "trainY = []\n",
    "testY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels from int to vectors\n",
    "trainY = np_utils.to_categorical(ytrain,12)\n",
    "testY = np_utils.to_categorical(ytest,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                        horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=28, height=28, depth=3, classes=12)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "2/1 [============================================================] - 2s 811ms/step - loss: 2.1788 - acc: 0.2442 - val_loss: 3.6280 - val_acc: 0.3333\n",
      "Epoch 2/50\n",
      "2/1 [============================================================] - 1s 383ms/step - loss: 2.3721 - acc: 0.4873 - val_loss: 2.2534 - val_acc: 0.2083\n",
      "Epoch 3/50\n",
      "2/1 [============================================================] - 1s 395ms/step - loss: 1.9650 - acc: 0.2303 - val_loss: 2.1848 - val_acc: 0.1250\n",
      "Epoch 4/50\n",
      "2/1 [============================================================] - 1s 391ms/step - loss: 2.0312 - acc: 0.1910 - val_loss: 2.1449 - val_acc: 0.3333\n",
      "Epoch 5/50\n",
      "2/1 [============================================================] - 1s 378ms/step - loss: 1.8074 - acc: 0.4184 - val_loss: 2.1874 - val_acc: 0.3333\n",
      "Epoch 6/50\n",
      "2/1 [============================================================] - 1s 388ms/step - loss: 1.9525 - acc: 0.3681 - val_loss: 2.3124 - val_acc: 0.3333\n",
      "Epoch 7/50\n",
      "2/1 [============================================================] - 1s 392ms/step - loss: 1.8590 - acc: 0.4410 - val_loss: 2.2312 - val_acc: 0.3333\n",
      "Epoch 8/50\n",
      "2/1 [============================================================] - 1s 469ms/step - loss: 1.9326 - acc: 0.3316 - val_loss: 2.0910 - val_acc: 0.3333\n",
      "Epoch 9/50\n",
      "2/1 [============================================================] - 1s 386ms/step - loss: 1.7299 - acc: 0.4774 - val_loss: 2.1012 - val_acc: 0.3333\n",
      "Epoch 10/50\n",
      "2/1 [============================================================] - 1s 379ms/step - loss: 1.6485 - acc: 0.5336 - val_loss: 2.2538 - val_acc: 0.3333\n",
      "Epoch 11/50\n",
      "2/1 [============================================================] - 1s 385ms/step - loss: 1.7191 - acc: 0.3947 - val_loss: 2.4593 - val_acc: 0.3333\n",
      "Epoch 12/50\n",
      "2/1 [============================================================] - 1s 388ms/step - loss: 1.8483 - acc: 0.3484 - val_loss: 2.3021 - val_acc: 0.3333\n",
      "Epoch 13/50\n",
      "2/1 [============================================================] - 1s 385ms/step - loss: 1.6209 - acc: 0.4311 - val_loss: 2.2097 - val_acc: 0.3333\n",
      "Epoch 14/50\n",
      "2/1 [============================================================] - 1s 418ms/step - loss: 1.6258 - acc: 0.4774 - val_loss: 2.1904 - val_acc: 0.3333\n",
      "Epoch 15/50\n",
      "2/1 [============================================================] - 1s 430ms/step - loss: 1.7304 - acc: 0.3681 - val_loss: 2.2167 - val_acc: 0.3333\n",
      "Epoch 16/50\n",
      "2/1 [============================================================] - 1s 455ms/step - loss: 1.8575 - acc: 0.3316 - val_loss: 2.2039 - val_acc: 0.3333\n",
      "Epoch 17/50\n",
      "2/1 [============================================================] - 1s 390ms/step - loss: 1.7026 - acc: 0.4410 - val_loss: 2.2074 - val_acc: 0.3333\n",
      "Epoch 18/50\n",
      "2/1 [============================================================] - 1s 396ms/step - loss: 1.6663 - acc: 0.4676 - val_loss: 2.3986 - val_acc: 0.3333\n",
      "Epoch 19/50\n",
      "2/1 [============================================================] - 1s 387ms/step - loss: 1.6415 - acc: 0.4410 - val_loss: 2.5299 - val_acc: 0.3333\n",
      "Epoch 20/50\n",
      "2/1 [============================================================] - 1s 408ms/step - loss: 1.8845 - acc: 0.3681 - val_loss: 2.1859 - val_acc: 0.3333\n",
      "Epoch 21/50\n",
      "2/1 [============================================================] - 1s 419ms/step - loss: 1.8136 - acc: 0.3218 - val_loss: 2.0935 - val_acc: 0.3333\n",
      "Epoch 22/50\n",
      "2/1 [============================================================] - 1s 384ms/step - loss: 1.8409 - acc: 0.4508 - val_loss: 2.0876 - val_acc: 0.3333\n",
      "Epoch 23/50\n",
      "2/1 [============================================================] - 1s 399ms/step - loss: 1.7526 - acc: 0.4213 - val_loss: 2.1222 - val_acc: 0.3333\n",
      "Epoch 24/50\n",
      "2/1 [============================================================] - 1s 381ms/step - loss: 1.6388 - acc: 0.5237 - val_loss: 2.4115 - val_acc: 0.3333\n",
      "Epoch 25/50\n",
      "2/1 [============================================================] - 1s 425ms/step - loss: 1.7225 - acc: 0.4045 - val_loss: 2.6607 - val_acc: 0.3333\n",
      "Epoch 26/50\n",
      "2/1 [============================================================] - 1s 433ms/step - loss: 1.9545 - acc: 0.3316 - val_loss: 2.3272 - val_acc: 0.3333\n",
      "Epoch 27/50\n",
      "2/1 [============================================================] - 1s 387ms/step - loss: 1.8489 - acc: 0.3385 - val_loss: 2.0886 - val_acc: 0.3333\n",
      "Epoch 28/50\n",
      "2/1 [============================================================] - 1s 388ms/step - loss: 1.6919 - acc: 0.4311 - val_loss: 2.0774 - val_acc: 0.3333\n",
      "Epoch 29/50\n",
      "2/1 [============================================================] - 1s 385ms/step - loss: 1.7040 - acc: 0.5139 - val_loss: 2.0864 - val_acc: 0.3333\n",
      "Epoch 30/50\n",
      "2/1 [============================================================] - 1s 386ms/step - loss: 1.7497 - acc: 0.3484 - val_loss: 2.1490 - val_acc: 0.3333\n",
      "Epoch 31/50\n",
      "2/1 [============================================================] - 1s 435ms/step - loss: 1.6186 - acc: 0.4144 - val_loss: 2.3730 - val_acc: 0.3333\n",
      "Epoch 32/50\n",
      "2/1 [============================================================] - 1s 416ms/step - loss: 1.5685 - acc: 0.3848 - val_loss: 2.5650 - val_acc: 0.3333\n",
      "Epoch 33/50\n",
      "2/1 [============================================================] - 1s 398ms/step - loss: 1.7386 - acc: 0.3947 - val_loss: 2.4473 - val_acc: 0.3333\n",
      "Epoch 34/50\n",
      "2/1 [============================================================] - 1s 408ms/step - loss: 1.4978 - acc: 0.5069 - val_loss: 2.2746 - val_acc: 0.3333\n",
      "Epoch 35/50\n",
      "2/1 [============================================================] - 1s 398ms/step - loss: 1.4912 - acc: 0.5266 - val_loss: 2.1668 - val_acc: 0.3333\n",
      "Epoch 36/50\n",
      "2/1 [============================================================] - 1s 436ms/step - loss: 1.7466 - acc: 0.5168 - val_loss: 2.1810 - val_acc: 0.3333\n",
      "Epoch 37/50\n",
      "2/1 [============================================================] - 1s 420ms/step - loss: 1.5566 - acc: 0.4537 - val_loss: 2.2817 - val_acc: 0.3750\n",
      "Epoch 38/50\n",
      "2/1 [============================================================] - 1s 438ms/step - loss: 1.4579 - acc: 0.4537 - val_loss: 2.2772 - val_acc: 0.3750\n",
      "Epoch 39/50\n",
      "2/1 [============================================================] - 1s 427ms/step - loss: 1.5843 - acc: 0.4803 - val_loss: 2.1318 - val_acc: 0.3333\n",
      "Epoch 40/50\n",
      "2/1 [============================================================] - 1s 484ms/step - loss: 1.4873 - acc: 0.4734 - val_loss: 2.0956 - val_acc: 0.2917\n",
      "Epoch 41/50\n",
      "2/1 [============================================================] - 1s 439ms/step - loss: 1.4293 - acc: 0.5168 - val_loss: 2.3090 - val_acc: 0.3750\n",
      "Epoch 42/50\n",
      "2/1 [============================================================] - 1s 401ms/step - loss: 1.3292 - acc: 0.5098 - val_loss: 2.3346 - val_acc: 0.3750\n",
      "Epoch 43/50\n",
      "2/1 [============================================================] - 1s 407ms/step - loss: 1.4466 - acc: 0.5561 - val_loss: 2.2315 - val_acc: 0.2917\n",
      "Epoch 44/50\n",
      "2/1 [============================================================] - 1s 393ms/step - loss: 1.7056 - acc: 0.3877 - val_loss: 2.2000 - val_acc: 0.2917\n",
      "Epoch 45/50\n",
      "2/1 [============================================================] - 1s 384ms/step - loss: 1.5245 - acc: 0.5463 - val_loss: 2.2828 - val_acc: 0.3750\n",
      "Epoch 46/50\n",
      "2/1 [============================================================] - 1s 380ms/step - loss: 1.4442 - acc: 0.5098 - val_loss: 2.3662 - val_acc: 0.3333\n",
      "Epoch 47/50\n",
      "2/1 [============================================================] - 1s 378ms/step - loss: 1.5730 - acc: 0.3877 - val_loss: 2.1985 - val_acc: 0.3750\n",
      "Epoch 48/50\n",
      "2/1 [============================================================] - 1s 380ms/step - loss: 1.4334 - acc: 0.5098 - val_loss: 2.0928 - val_acc: 0.3333\n",
      "Epoch 49/50\n",
      "2/1 [============================================================] - 1s 375ms/step - loss: 1.5976 - acc: 0.4635 - val_loss: 2.0930 - val_acc: 0.3333\n",
      "Epoch 50/50\n",
      "2/1 [============================================================] - 1s 383ms/step - loss: 1.5449 - acc: 0.4172 - val_loss: 2.1699 - val_acc: 0.3750\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy \n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Label Prediction\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('figure.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows chart in a popup. Close to keep going\n",
    "#chart = cv2.imread('figure.png',1)\n",
    "#cv2.imshow('Results',chart)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape original input data images for predicting\n",
    "img_check = np.array(img_list, dtype =\"float\")/225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsMade = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all data through the prediction model that was created\n",
    "for i in range (0,len(img_check)):\n",
    "    predIndex = np.where(preds[i] == np.amax(preds[i]))\n",
    "    prediction = int(predIndex[0][0])\n",
    "    predictionsMade.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many correct predictions were made\n",
    "correct = 0\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    if(predictionsMade[i] == yset[i]):\n",
    "        correct += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(correct/len(yset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate back to original csv label names\n",
    "finalPred = []\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    finalPred.append(yval_label[predictionsMade[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the new column\n",
    "df['#predictions'] = finalPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new file name and save\n",
    "new_file =  csv_file[:-4]+'_v1.csv'\n",
    "df.to_csv(new_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
